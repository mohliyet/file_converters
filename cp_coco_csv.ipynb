{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "# Function to calculate IoU (Intersection over Union)\n",
    "def calculate_iou(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    x_left = max(x1, x2)\n",
    "    y_top = max(y1, y2)\n",
    "    x_right = min(x1 + w1, x2 + w2)\n",
    "    y_bottom = min(y1 + h1, y2 + h2)\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "    iou = intersection_area / (box1_area + box2_area - intersection_area)\n",
    "    return iou\n",
    "\n",
    "# Function to process files based on ground truth and prediction JSONs\n",
    "def process_files(gt_file, prediction_file):\n",
    "    # Load ground truth annotations\n",
    "    with open(gt_file, \"r\") as f:\n",
    "        gt_data = json.load(f)\n",
    "\n",
    "    # Load prediction annotations\n",
    "    with open(prediction_file, \"r\") as f:\n",
    "        pred_data = json.load(f)\n",
    "\n",
    "    # Create defaultdict to store annotations by filename\n",
    "    annotations = defaultdict(list)\n",
    "    matched_predictions = set()\n",
    "\n",
    "    # Index annotations by image_id\n",
    "    gt_annotations_by_image = defaultdict(list)\n",
    "    for ann in gt_data['annotations']:\n",
    "        gt_annotations_by_image[ann['image_id']].append(ann)\n",
    "    \n",
    "    pred_annotations_by_image = defaultdict(list)\n",
    "    for ann in pred_data:\n",
    "        pred_annotations_by_image[ann['image_id']].append(ann)\n",
    "\n",
    "    # Process each image in ground truth data\n",
    "    for img in gt_data['images']:\n",
    "        image_id = img['id']\n",
    "        filename = img['file_name']\n",
    "        img_width = img['width']\n",
    "        img_height = img['height']\n",
    "\n",
    "        # Fetch annotations for current image from both ground truth and predictions\n",
    "        gt_annotations = gt_annotations_by_image[image_id]\n",
    "        pred_annotations = pred_annotations_by_image[image_id]\n",
    "\n",
    "        # Process each ground truth annotation\n",
    "        for gt_obj in gt_annotations:\n",
    "            gt_box = gt_obj['bbox']\n",
    "            gt_obj_id = gt_obj['category_id']\n",
    "            matched_pred = None\n",
    "            max_iou = 0\n",
    "            \n",
    "            # Find the best matching prediction based on IoU\n",
    "            for pred_obj in pred_annotations:\n",
    "                iou = calculate_iou(gt_box, pred_obj['bbox'])\n",
    "                if iou > max_iou:\n",
    "                    max_iou = iou\n",
    "                    matched_pred = pred_obj\n",
    "            \n",
    "            # If a matching prediction is found and IoU is sufficient\n",
    "            if matched_pred and max_iou >= 0.5:\n",
    "                # Use a tuple of relevant values as a unique identifier in matched_predictions\n",
    "                pred_tuple = (\n",
    "                    matched_pred['category_id'], \n",
    "                    tuple(matched_pred['bbox']),\n",
    "                    matched_pred.get('score', None),\n",
    "                    tuple(matched_pred['score_all'])\n",
    "                )\n",
    "                matched_predictions.add(pred_tuple)\n",
    "                \n",
    "                annotations[filename].append(\n",
    "                    [filename, img_width, img_height, gt_obj_id] + gt_box + \n",
    "                    [matched_pred['category_id']] + matched_pred['bbox'] + \n",
    "                    [matched_pred.get('score', None)] + list(matched_pred['score_all'])  # Add score_all values\n",
    "                )\n",
    "            else:\n",
    "                # Handle unmatched ground truth annotations\n",
    "                annotations[filename].append(\n",
    "                    [filename, img_width, img_height, gt_obj_id] + gt_box + \n",
    "                    [None, None, None, None, None, None, None] +  # Blank columns for score_all\n",
    "                    [None] * len(pred_data[0]['score_all'])  # Ensure correct number of blank entries\n",
    "                )\n",
    "\n",
    "        # Process unmatched predictions\n",
    "        for pred_obj in pred_annotations:\n",
    "            # Check if prediction is not already matched using a similar approach\n",
    "            pred_tuple = (\n",
    "                pred_obj['category_id'], \n",
    "                tuple(pred_obj['bbox']),\n",
    "                pred_obj.get('score', None),\n",
    "                tuple(pred_obj['score_all'])\n",
    "            )\n",
    "            if pred_tuple not in matched_predictions:\n",
    "                annotations[filename].append(\n",
    "                    [filename, img_width, img_height, None, None, None, None, None] + \n",
    "                    [pred_obj['category_id']] + pred_obj['bbox'] + \n",
    "                    [pred_obj.get('score', None)] + list(pred_obj['score_all'])  # Add score_all values\n",
    "                )\n",
    "\n",
    "    return annotations\n",
    "\n",
    "# Function to write annotations to CSV\n",
    "def write_to_csv(annotations, output_csv):\n",
    "    with open(output_csv, \"w\", newline=\"\") as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        headers = [\n",
    "            \"filename\", \"image_width\", \"image_height\", \"gt_obj_id\", \"gt_x\", \"gt_y\", \"gt_width\", \"gt_height\", \n",
    "            \"pred_obj_id\", \"pred_x\", \"pred_y\", \"pred_width\", \"pred_height\", \"conf_score\"\n",
    "        ]\n",
    "        \n",
    "        # Add headers for score_all columns dynamically\n",
    "        num_classes = len(next(iter(annotations.values()))[0]) - len(headers)\n",
    "        for i in range(num_classes):\n",
    "            headers.append(f\"class_{i}_conf_score\")\n",
    "        \n",
    "        csv_writer.writerow(headers)\n",
    "        \n",
    "        for filename, ann_list in annotations.items():\n",
    "            for ann in ann_list:\n",
    "                csv_writer.writerow(ann)\n",
    "\n",
    "# Define paths and files based on provided information\n",
    "gt_file = \"valid.json\"\n",
    "prediction_file = \"faster_rcnn.json\"\n",
    "output_csv = \"faster_rcnn.csv\"\n",
    "\n",
    "# Process files and write annotations to CSV\n",
    "annotations = process_files(gt_file, prediction_file)\n",
    "write_to_csv(annotations, output_csv)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
